{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the diagnosis of a skin condition based on its image in the HAM10000 dataset, I used VGG as a feature extractor to convert each image into a numpy array of numerical features and fit several classifier models (SVM, Naive-Bayes, DecisionTree, and RandomForestClassifier) over it.\n",
    "\n",
    "The code for the feature extraction process was partially based on https://medium.com/@franky07724_57962/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG is a convolutional neural network model for image recognition proposed by the Visual Geometry Group from the University of Oxford that achieved 92.7% top-5 test accuracy in ImageNet, a dataset of over 14 million images belonging to 1000 classes.  The input layer accepts a 224 x 224 RGB image, and the output layer is a softmax prediction on 1000 classes. Between the two, VGG16 contains 16 weight layers, and VGG19 contains 19 weight layers.\n",
    "\n",
    "By removing the output layer (as I did with the include_top = False parameter), VGG can be used as a feature extractor. I applied this feature extractor over every image in half of the dataset (our training data) and appended the results into a single pandas dataframe with the identification code of each image (image_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Creating the model\n",
    "model = VGG16(include_top=False)\n",
    "\n",
    "#Function for feature extraction\n",
    "def feature_extract(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "\n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    return vgg16_feature_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of the features\n",
    "vgg16_feature_list = []\n",
    "\n",
    "#Globbing the files\n",
    "images = glob.glob(r'C:\\Users\\songs\\Desktop\\CSV files\\dataverse_files\\HAM10000_images_part_1\\*')\n",
    "image_urls =  []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image_urls.append(images[i])\n",
    "    vgg16_feature_np = feature_extract(images[i])\n",
    "    vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "    print(i)\n",
    "\n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "\n",
    "#Creating a DataFrame containing the image information.\n",
    "features = pd.DataFrame(vgg16_feature_list_np)\n",
    "image_names = re.findall('ISIC_[0-9]{7}',str(image_urls))\n",
    "features['image_id'] = image_names\n",
    "\n",
    "#Adding the diagnoses.\n",
    "img_features = features.merge(right = data[['image_id','dx']], how='inner', on = 'image_id')\n",
    "features.to_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with fitting models over the data, I used PCA (Principal Component Analysis) to reduce the number of features in image features dataframe. \n",
    "\n",
    "I performed a dimension reduction because the image features dataframe contains 25088 features, not including image_id and the diagnosis. This large number of features is very troublesome for several reasons: First, they could induce noise when making the final predictions; second, a dataframe with 25087 columns would be very time-consuming to load. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I took a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25080</th>\n",
       "      <th>25081</th>\n",
       "      <th>25082</th>\n",
       "      <th>25083</th>\n",
       "      <th>25084</th>\n",
       "      <th>25085</th>\n",
       "      <th>25086</th>\n",
       "      <th>25087</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.640642</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>ISIC_0024306</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.990223</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.183280</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.999651</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>ISIC_0024307</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.352508</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.049744</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.286820</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6.038150</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>ISIC_0024308</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.653627</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.307326</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.370319</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.370927</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>ISIC_0024309</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>15.096593</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.645373</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5.191962</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>9.431757</td>\n",
       "      <td>14.747563</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>ISIC_0024310</td>\n",
       "      <td>mel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1          2    3    4         5    6    7    8    9  ...  \\\n",
       "0 -0.000000 -0.0  -0.000000 -0.0 -0.0 -0.000000 -0.0 -0.0 -0.0 -0.0  ...   \n",
       "1  5.990223 -0.0  -0.000000 -0.0 -0.0 -0.000000 -0.0 -0.0 -0.0 -0.0  ...   \n",
       "2  5.352508 -0.0   1.049744 -0.0 -0.0 -0.000000 -0.0 -0.0 -0.0 -0.0  ...   \n",
       "3 -0.000000 -0.0   0.653627 -0.0 -0.0 -0.000000 -0.0 -0.0 -0.0 -0.0  ...   \n",
       "4 -0.000000 -0.0  15.096593 -0.0 -0.0  4.645373 -0.0 -0.0 -0.0 -0.0  ...   \n",
       "\n",
       "       25080     25081  25082     25083     25084     25085      25086  25087  \\\n",
       "0   4.640642 -0.000000   -0.0 -0.000000 -0.000000 -0.000000  -0.000000   -0.0   \n",
       "1  18.183280 -0.000000   -0.0 -0.000000  1.999651 -0.000000  -0.000000   -0.0   \n",
       "2  26.286820 -0.000000   -0.0 -0.000000 -0.000000 -0.000000   6.038150   -0.0   \n",
       "3   4.307326 -0.000000   -0.0  2.370319 -0.000000 -0.000000   0.370927   -0.0   \n",
       "4  -0.000000  5.191962   -0.0 -0.000000 -0.000000  9.431757  14.747563   -0.0   \n",
       "\n",
       "       image_id   dx  \n",
       "0  ISIC_0024306   nv  \n",
       "1  ISIC_0024307   nv  \n",
       "2  ISIC_0024308   nv  \n",
       "3  ISIC_0024309   nv  \n",
       "4  ISIC_0024310  mel  \n",
       "\n",
       "[5 rows x 25090 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the saved .csv file and dropping some columns that got added in the feature extraction process.\n",
    "df_img_features = pd.read_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\test.csv')\n",
    "df_img_features = df_img_features.drop([df_img_features.columns[0],df_img_features.columns[1]], axis=1)\n",
    "df_img_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 25090)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the data has a total of 4997 samples with each having 25088 features. I will then see how many of these features have significant variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension reduction using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying PCA, I standardized the image features so that scale would not bias the final feature selection. As can be seen below, I first visualized the cumulative distribution of the explained variance entered 0.95 as a parameter to the PCA function to select for the number of features needed to capture 95% of the variance. Out of 25088 features, only 2831 features were needed to capture 95% of the variance. By shortening the number of features, I significantly reduced the size of the dataframe.\n",
    "\n",
    "When I fit the classifiers over the data, I'll compare the prediction efficacy between the reduced and the unreduced image features to see if the dimension reduction was effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Visualizing with 30 components first\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making the predictor dataframe and fitting the PCA model on it.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np_img_features = df_img_features.drop(['image_id','dx'], axis = 1).values\n",
    "scaled_img_features = StandardScaler().fit_transform(np_img_features)\n",
    "pca.fit(scaled_img_features)\n",
    "\n",
    "\n",
    "#Graphing the data\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.title('Visualization of feature variances')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('Cumulative explaned variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2821</th>\n",
       "      <th>2822</th>\n",
       "      <th>2823</th>\n",
       "      <th>2824</th>\n",
       "      <th>2825</th>\n",
       "      <th>2826</th>\n",
       "      <th>2827</th>\n",
       "      <th>2828</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.197622</td>\n",
       "      <td>7.265878</td>\n",
       "      <td>-2.550361</td>\n",
       "      <td>-0.159952</td>\n",
       "      <td>7.448056</td>\n",
       "      <td>1.649885</td>\n",
       "      <td>0.387693</td>\n",
       "      <td>1.835810</td>\n",
       "      <td>2.950036</td>\n",
       "      <td>-9.277368</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.764403</td>\n",
       "      <td>-0.715089</td>\n",
       "      <td>-3.602659</td>\n",
       "      <td>-2.630041</td>\n",
       "      <td>-0.045274</td>\n",
       "      <td>-4.286926</td>\n",
       "      <td>0.327192</td>\n",
       "      <td>-0.959964</td>\n",
       "      <td>ISIC_0024306</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.815952</td>\n",
       "      <td>15.027976</td>\n",
       "      <td>-7.397805</td>\n",
       "      <td>-4.025595</td>\n",
       "      <td>15.197397</td>\n",
       "      <td>7.608394</td>\n",
       "      <td>-0.146302</td>\n",
       "      <td>2.479199</td>\n",
       "      <td>6.638179</td>\n",
       "      <td>-6.331796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091350</td>\n",
       "      <td>0.983975</td>\n",
       "      <td>1.412068</td>\n",
       "      <td>0.751271</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>2.275187</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>-0.113624</td>\n",
       "      <td>ISIC_0024307</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.318244</td>\n",
       "      <td>2.535372</td>\n",
       "      <td>18.519314</td>\n",
       "      <td>-2.283010</td>\n",
       "      <td>4.328701</td>\n",
       "      <td>-7.302797</td>\n",
       "      <td>-5.529607</td>\n",
       "      <td>-1.425039</td>\n",
       "      <td>-4.626797</td>\n",
       "      <td>1.722985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639068</td>\n",
       "      <td>-0.527473</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>1.180825</td>\n",
       "      <td>0.065463</td>\n",
       "      <td>-0.365549</td>\n",
       "      <td>0.309908</td>\n",
       "      <td>-1.439344</td>\n",
       "      <td>ISIC_0024308</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.684587</td>\n",
       "      <td>-9.815083</td>\n",
       "      <td>-7.842098</td>\n",
       "      <td>8.017347</td>\n",
       "      <td>-1.179181</td>\n",
       "      <td>2.815549</td>\n",
       "      <td>3.228892</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>5.368839</td>\n",
       "      <td>-4.451693</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.075900</td>\n",
       "      <td>-0.109621</td>\n",
       "      <td>3.483772</td>\n",
       "      <td>1.325750</td>\n",
       "      <td>-1.946950</td>\n",
       "      <td>0.179406</td>\n",
       "      <td>1.323368</td>\n",
       "      <td>-0.356334</td>\n",
       "      <td>ISIC_0024309</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.597737</td>\n",
       "      <td>-14.925823</td>\n",
       "      <td>-23.469787</td>\n",
       "      <td>2.128299</td>\n",
       "      <td>4.329971</td>\n",
       "      <td>5.915953</td>\n",
       "      <td>-12.924405</td>\n",
       "      <td>7.572073</td>\n",
       "      <td>11.535136</td>\n",
       "      <td>5.370676</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480355</td>\n",
       "      <td>0.267202</td>\n",
       "      <td>0.564269</td>\n",
       "      <td>0.808265</td>\n",
       "      <td>0.689129</td>\n",
       "      <td>-0.752351</td>\n",
       "      <td>-0.177477</td>\n",
       "      <td>-0.405549</td>\n",
       "      <td>ISIC_0024310</td>\n",
       "      <td>mel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2831 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3          4         5          6  \\\n",
       "0 -17.197622   7.265878  -2.550361 -0.159952   7.448056  1.649885   0.387693   \n",
       "1 -17.815952  15.027976  -7.397805 -4.025595  15.197397  7.608394  -0.146302   \n",
       "2 -12.318244   2.535372  18.519314 -2.283010   4.328701 -7.302797  -5.529607   \n",
       "3  -0.684587  -9.815083  -7.842098  8.017347  -1.179181  2.815549   3.228892   \n",
       "4  32.597737 -14.925823 -23.469787  2.128299   4.329971  5.915953 -12.924405   \n",
       "\n",
       "          7          8         9  ...      2821      2822      2823      2824  \\\n",
       "0  1.835810   2.950036 -9.277368  ... -4.764403 -0.715089 -3.602659 -2.630041   \n",
       "1  2.479199   6.638179 -6.331796  ... -0.091350  0.983975  1.412068  0.751271   \n",
       "2 -1.425039  -4.626797  1.722985  ... -0.639068 -0.527473  0.095943  1.180825   \n",
       "3  0.097971   5.368839 -4.451693  ... -2.075900 -0.109621  3.483772  1.325750   \n",
       "4  7.572073  11.535136  5.370676  ...  1.480355  0.267202  0.564269  0.808265   \n",
       "\n",
       "       2825      2826      2827      2828      image_id   dx  \n",
       "0 -0.045274 -4.286926  0.327192 -0.959964  ISIC_0024306   nv  \n",
       "1 -0.053542  2.275187  0.225434 -0.113624  ISIC_0024307   nv  \n",
       "2  0.065463 -0.365549  0.309908 -1.439344  ISIC_0024308   nv  \n",
       "3 -1.946950  0.179406  1.323368 -0.356334  ISIC_0024309   nv  \n",
       "4  0.689129 -0.752351 -0.177477 -0.405549  ISIC_0024310  mel  \n",
       "\n",
       "[5 rows x 2831 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming the image data so that it only contains 6 features.\n",
    "pca = PCA(0.95)\n",
    "pca_features = pca.fit_transform(scaled_img_features)\n",
    "df_pca_features = pd.DataFrame(pca_features)\n",
    "df_pca_features[['image_id','dx']] = df_img_features[['image_id','dx']]\n",
    "df_pca_features.to_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\pca.csv')\n",
    "df_pca_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using train_test_split, I split the metadata, unreduced image feature data, reduced image feature data, and a dataframe containing a combination of the reduced image feature data with the correponding patient's metadata into \"training\" and \"testing\" sets consisting 70% and 30% of the total data, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10015, 7)\n"
     ]
    }
   ],
   "source": [
    "#Importing the csv file\n",
    "df_metadata = pd.read_csv(r'C:\\Users\\songs\\Desktop\\CSV files\\dataverse_files\\HAM10000_metadata.csv',index_col=0)\n",
    "print(df_metadata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata contains information about patients in all 10015 images, instead of the 4997 in my training set. Thus, I selected only for images contained in the image feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We only want the metadata which is contained in the training set, as opposed to all 10015 images.\n",
    "df_metadata = df_metadata.loc[df_metadata['image_id'].isin(df_img_features['image_id'])]\n",
    "df_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "5  HAM_0001466  ISIC_0027850  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting categorical variables to type \"category\" for pd.get_dummies later.\n",
    "df_metadata['dx_type'] = df_metadata['dx_type'].astype('category')\n",
    "df_metadata['sex'] = df_metadata['sex'].astype('category')\n",
    "df_metadata['localization'] = df_metadata['localization'].astype('category')\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the predictor columns (X_meta), I dropped both the lesion and the image id columns because they are unlikely to be of any help in the prediction process and may introduce unnecessary noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target and predictor columns\n",
    "y_meta = df_metadata['dx'].values\n",
    "X_meta = pd.get_dummies(df_metadata.drop(['lesion_id','image_id','dx'], axis = 1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test dataset\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(X_meta, y_meta, \n",
    "                                                                        test_size = 0.3, random_state=101, stratify=y_meta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_features = pd.read_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target and predictor columns\n",
    "y_pca = df_pca_features['dx'].values\n",
    "X_pca = df_pca_features.drop(['image_id','dx'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test dataset\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, \n",
    "                                                                    test_size=0.3, random_state=101, stratify=y_pca) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unreduced image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target and predictor columns\n",
    "y_img = df_img_features['dx'].values\n",
    "X_img = df_img_features.drop(['image_id','dx'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test dataset\n",
    "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(X_img, y_img, \n",
    "                                                                    test_size=0.3, random_state=101, stratify=y_img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining image feature and tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_metadata.merge(right=df_pca_features, how='inner', on=['image_id','dx'])\n",
    "df_combined.to_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\whole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>2819</th>\n",
       "      <th>2820</th>\n",
       "      <th>2821</th>\n",
       "      <th>2822</th>\n",
       "      <th>2823</th>\n",
       "      <th>2824</th>\n",
       "      <th>2825</th>\n",
       "      <th>2826</th>\n",
       "      <th>2827</th>\n",
       "      <th>2828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>3111</td>\n",
       "      <td>10.583895</td>\n",
       "      <td>-8.562058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>-0.832050</td>\n",
       "      <td>-0.117147</td>\n",
       "      <td>-1.279545</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.087504</td>\n",
       "      <td>2.492885</td>\n",
       "      <td>0.263184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>723</td>\n",
       "      <td>63.828696</td>\n",
       "      <td>-6.275236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375517</td>\n",
       "      <td>0.111168</td>\n",
       "      <td>-0.381691</td>\n",
       "      <td>0.757508</td>\n",
       "      <td>-0.257798</td>\n",
       "      <td>0.481867</td>\n",
       "      <td>-0.165353</td>\n",
       "      <td>-1.201783</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.867134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2462</td>\n",
       "      <td>2.891863</td>\n",
       "      <td>-2.301103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871344</td>\n",
       "      <td>1.263791</td>\n",
       "      <td>-2.939438</td>\n",
       "      <td>-1.156450</td>\n",
       "      <td>0.124147</td>\n",
       "      <td>0.799442</td>\n",
       "      <td>-2.828278</td>\n",
       "      <td>-0.909289</td>\n",
       "      <td>-0.579126</td>\n",
       "      <td>-1.361526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>1354</td>\n",
       "      <td>34.999192</td>\n",
       "      <td>11.728751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448185</td>\n",
       "      <td>-0.375706</td>\n",
       "      <td>0.393892</td>\n",
       "      <td>0.087780</td>\n",
       "      <td>0.166572</td>\n",
       "      <td>0.275787</td>\n",
       "      <td>-0.312343</td>\n",
       "      <td>-0.210616</td>\n",
       "      <td>0.069709</td>\n",
       "      <td>-0.572029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>3541</td>\n",
       "      <td>96.871172</td>\n",
       "      <td>33.728998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139092</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>-0.114074</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>-0.103402</td>\n",
       "      <td>-0.157379</td>\n",
       "      <td>0.226258</td>\n",
       "      <td>0.186571</td>\n",
       "      <td>0.109356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2837 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0027850  bkl   histo  75.0  male          ear   \n",
       "\n",
       "   Unnamed: 0.1          0          1  ...      2819      2820      2821  \\\n",
       "0          3111  10.583895  -8.562058  ...  0.077396 -0.417588  0.038741   \n",
       "1           723  63.828696  -6.275236  ... -0.375517  0.111168 -0.381691   \n",
       "2          2462   2.891863  -2.301103  ...  0.871344  1.263791 -2.939438   \n",
       "3          1354  34.999192  11.728751  ...  0.448185 -0.375706  0.393892   \n",
       "4          3541  96.871172  33.728998  ...  0.139092 -0.001738 -0.114074   \n",
       "\n",
       "       2822      2823      2824      2825      2826      2827      2828  \n",
       "0 -0.832050 -0.117147 -1.279545  0.392000  0.087504  2.492885  0.263184  \n",
       "1  0.757508 -0.257798  0.481867 -0.165353 -1.201783  0.585288  0.867134  \n",
       "2 -1.156450  0.124147  0.799442 -2.828278 -0.909289 -0.579126 -1.361526  \n",
       "3  0.087780  0.166572  0.275787 -0.312343 -0.210616  0.069709 -0.572029  \n",
       "4  0.080431  0.006198 -0.103402 -0.157379  0.226258  0.186571  0.109356  \n",
       "\n",
       "[5 rows x 2837 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv('C:\\\\Users\\\\songs\\\\Desktop\\\\CSV files\\\\whole.csv',index_col=0)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target and predictor columns\n",
    "y_comb = df_combined['dx'].values\n",
    "X_comb = pd.get_dummies(df_combined.drop(['lesion_id','image_id','dx'], axis = 1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test dataset\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(X_comb, y_comb, \n",
    "                                                                        test_size=0.3, random_state=101, stratify=y_comb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting classifier models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I fitted the split data to the following models:\n",
    "* SVM (LinearSVC)\n",
    "* Naive Bayes (MultinomialNB)\n",
    "* DecisionTree\n",
    "* RandomForestClassifier\n",
    "\n",
    "For parameter optimization, I used GridSearchCV with f1_score as the scoring method. I chose this method because 1) the data is imbalanced, so accuracy is not a robust measurement 2) it takes into account both precision and recall, providing a more effective measurement of the classifier's accuracy.\n",
    "\n",
    "To see whether the metadata, unreduced image feature data, reduced image feature data, or a combination of image and metadata is the most effective for classification, I fitted each model used with each dataset and compared their f1-scores to see which dataset yielded the best results, and to see whether there is a pattern across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "\n",
    "In this notebook, I'm going to document how I tuned the hyperparameters for my models and what they are. While I briefly discuss the results, I am not going to document all of the F-scores I got here in detail; for that please look at the final report in the \"reports\" folder on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the datasets\n",
    "datasets = [(X_train_meta, X_test_meta, y_train_meta, y_test_meta),\n",
    "                (X_train_pca, X_test_pca, y_train_pca, y_test_pca),\n",
    "                (X_train_img, X_test_img, y_train_img, y_test_img),\n",
    "                (X_train_comb, X_test_comb, y_train_comb, y_test_comb)]\n",
    "dataset_names = ['metadata','pca','img','comb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params(model, params, X_train, y_train):\n",
    "    \"\"\"Select the best parameters out of a dict for a model given training data\"\"\"\n",
    "    clf = model(max_iter=100000)\n",
    "    clf_cv = RandomizedSearchCV(clf, param_distributions=params, scoring='f1_micro',verbose=10)\n",
    "    clf_cv.fit(X_train, y_train)\n",
    "    return clf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, best_params, X_train, y_train):\n",
    "    \"\"\"Returns a fitted model given training data\"\"\"\n",
    "    if model == GaussianNB:\n",
    "        clf = model()\n",
    "    else:\n",
    "        clf = model(**best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_fit = clf\n",
    "    return model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_f1(model):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used LinearSVC instead of SVC here mostly out of consideration for computational time, since there is a dataset with 25088 features and SVM is infamous for the large amount of parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params_to_test = {'loss': ['hinge', 'squared_hinge'], \n",
    "                  'C':np.arange(0.5, 5.5, 0.5), \n",
    "                  'multi_class' : ['ovr','crammer_singer']}\n",
    "params_svm = []\n",
    "for data in tqdm(datasets):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    param = optimize_params(svm.LinearSVC, params=params_to_test, X_train=X_train, y_train=y_train)\n",
    "    params_svm.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'multi_class': 'ovr', 'loss': 'squared_hinge', 'C': 2.0},\n",
       " {'multi_class': 'crammer_singer', 'loss': 'squared_hinge', 'C': 0.5},\n",
       " {'multi_class': 'crammer_singer', 'loss': 'hinge', 'C': 1.0},\n",
       " {'multi_class': 'crammer_singer', 'loss': 'hinge', 'C': 5.0}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    X_train, X_test, y_train, y_test = datasets[i]\n",
    "    model = fit_model(svm.LinearSVC, best_params=params_svm[i], X_train=X_train, y_train=y_train)\n",
    "    filename = 'SVM_' + dataset_names[i] + '.model'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-scores ranged from 0.65 to 0.77, and of the four, the unreduced image features achieved the highest f1-score (0.67). Surprisingly, the unreduced image features performed better than the reduced image features in LinearSVC. Perhaps there were information in the unreduced image features that helped adumbrate the decision boundaries, or perhaps the other datasets would have beeen better fitted with a nonlinear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of Naive-Bayes models available in scikit-learn. Just to list a few, BinomialNB is designed for data with categorical variables that are binary in nature, MultinomialNB is for use with multinomial prediction, and ComplementNB is supposed to help with unbalanced data. \n",
    "\n",
    "In this case, I chose GaussianNB because it is most compatible with numerical (continuous) data. This is important, since there is a large number of negative numerical values included in datasets with image features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(len(datasets)):\n",
    "    X_train, X_test, y_train, y_test = data[i]\n",
    "    model = fit_model(GaussianNB, X_train, y_train)\n",
    "    filename = 'NB_' + dataset_names[i] +'.model'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-scores ranged from 0.51 to 0.66, and of the four, the reduced image features achieved the highest f1-score (0.66). As expected of GaussianNB, datasets with only continuous values performed better than those containing categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_to_test = {'max_depth': np.arange(5,55,10), \n",
    "                  'min_samples_split': range(2,10),\n",
    "                  'min_samples_leaf': range(1,10)}\n",
    "params_dt = []\n",
    "for data in datasets:\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    param = optimize_params(DecisionTreeClassifier, params=params_to_test, X_train=X_train, y_train=y_train)\n",
    "    params_dt.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'min_samples_split': 8, 'min_samples_leaf': 9, 'max_depth': 5},\n",
       " {'min_samples_split': 5, 'min_samples_leaf': 8, 'max_depth': 5},\n",
       " {'min_samples_split': 7, 'min_samples_leaf': 3, 'max_depth': 5},\n",
       " {'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 5}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    X_train, X_test, y_train, y_test = datasets[i]\n",
    "    model = fit_model(DecisionTreeClassifier, best_params=params_dt[i], X_train=X_train, y_train=y_train)\n",
    "    filename = 'DT_' + dataset_names[i] +'.model'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-scores ranged from 0.63 to 0.73, and of the four, the metadata and the combination tied for the highest f-score. Generally, DecisionTreeClassifier appears to be a more robust classifier compared to Naive Bayes. Perhaps this is because of some interaction between variables that Naive Bayes couldn't capture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_test = {'n_estimators': np.arange(10,100,10), \n",
    "                  'max_depth': np.arange(5,55,10), \n",
    "                  'min_samples_split': range(2,10),\n",
    "                  'min_samples_leaf': range(1,10)}\n",
    "params_rfc = []\n",
    "for data in datasets:\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    param = optimize_params(RandomForestClassifier, params=params_to_test, X_train=X_train, y_train=y_train)\n",
    "    params_rfc.append(param)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_estimators': 10,\n",
       "  'min_samples_split': 6,\n",
       "  'min_samples_leaf': 3,\n",
       "  'max_depth': 15},\n",
       " {'n_estimators': 30,\n",
       "  'min_samples_split': 3,\n",
       "  'min_samples_leaf': 3,\n",
       "  'max_depth': 35},\n",
       " {'n_estimators': 20,\n",
       "  'min_samples_split': 4,\n",
       "  'min_samples_leaf': 2,\n",
       "  'max_depth': 35},\n",
       " {'n_estimators': 70,\n",
       "  'min_samples_split': 6,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_depth': 25}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    X_train, X_test, y_train, y_test = datasets[i]\n",
    "    model = fit_model(RandomForestClassifier, best_params=params_rfc[i], X_train=X_train, y_train=y_train)\n",
    "    filename = 'RFC_' + dataset_names[i] +'.model'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-scores ranged from 0.7 to 0.75, and the combination of image data and metadata performed the best (f-score 0.75). Across all datasets aside from the metadata, RandomForest achieved higher f1-scores compared to DecisionTree, with the most improvement seen in data containing numerical values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
