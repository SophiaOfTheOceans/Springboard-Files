{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature addition and reduction\n",
    "\n",
    "As seen in the inferential statistics notebook, there are a lot of multicollinearities between our variables. In this notebook I will try to delete some redundant features and add some features, learning from the EDA, that I think might be helpful for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load necessary modules\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\songs\\Desktop\\Springboard Files\\Capstone 2\\data\\Interim\\train1.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Markdown Columns\n",
    "\n",
    "As seen in the EDA notebook, the markdown columns are highly correlated with each other and a large source of multicollinearity. By combining them into one \"Total_Markdown\" column, we reduce collinearity. We can also eliminate the IsMarkDown column, since a total markdown of 0 would mean that there is no markdown that week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totalmd = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Type_barplot\n",
    "\n",
    "I had originally created this column for easier plotting in seaborn, but now that we're not doing plotting, we can delete the column. \n",
    "\n",
    "Type of store is a categorical variable, and when doing regression, it's important to have a baseline for categorical variables so that we can interpret the effect of other options in the category. I chose type B as the baseline because it is in the middle in terms of size, and it's be easy to see positive effects (Type A) or negative effects (Type C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nob = df_totalmd.drop(['Type_barplot','Type_B'],axis=1)\n",
    "df_nob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciphering Year, Month, Week of Year, and Day\n",
    "\n",
    "The year, month, week, and day could have an impact on the revenue made. As of now, the date column won't work with a lot of models. Thus, I'm going to parse the date column into year, month week of year, and day columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsedate = df_nob\n",
    "df_parsedate['Date'] = df_parsedate['Date'].astype('datetime64')\n",
    "df_parsedate['Year'] = df_nob['Date'].dt.year\n",
    "df_parsedate['Month'] = df_nob['Date'].dt.month\n",
    "df_parsedate['Week_of_year'] = df_nob['Date'].dt.weekofyear\n",
    "df_parsedate['Day'] = df_nob['Date'].dt.day\n",
    "df_parsedate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsedate.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Yearly Median value of each Store-Dept combination\n",
    "\n",
    "This would provide a baseline value for each store-department combination that the models could modify for each week given the other attributes. I'm using the median instead of the mean because the mean can be biased by extreme values, and thus won't give as clear an indicator of each store-department's average performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df_parsedate.groupby(['Store','Dept','Year'])['Weekly_Sales'].median()\n",
    "df_median = df_parsedate.merge(df_groupby, on=['Store','Dept','Year'], how='outer')\n",
    "df_median.rename(columns={'Weekly_Sales_x':'Weekly_Sales','Weekly_Sales_y':'Median_Sales'}, inplace=True)\n",
    "df_median.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding some Date variables\n",
    "\n",
    "Some models don't work well with the dates, so I'm going to see if any dates have a larger impact than others.\n",
    "\n",
    "From from the >$300,000 table in the EDA notebook, it appears that a signficant portion of them are made in the thanksgiving week, so we'll make a new feature called \"IsThanksgiving\" to distinguish those values made during Thanksgiving weeks. Looking at the average sales per week, it appears that sales are higher near Christmas, so I'll also create a new feature called \"IsChristmas\". After this, we could delete the Date Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigholidays = df_median\n",
    "df_bigholidays['IsThanksgiving'] = (df_bigholidays['Date'] == '2011-11-25') | (df_bigholidays['Date'] == '2010-11-26')\n",
    "df_bigholidays['IsChristmas'] = (df_bigholidays['Date'] == '2010-12-31') | (df_bigholidays['Date'] == '2011-12-30')\n",
    "df_bigholidays = df_bigholidays.drop('Date',axis=1)\n",
    "df_bigholidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigholidays.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding department 72\n",
    "\n",
    "Looking at the EDA, it appears that department 72 has sales higher than others. I'll create an \"IsDept72\" Column, then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept72 = df_bigholidays\n",
    "df_dept72['IsDept72'] = (df_bigholidays['Dept'] == 72)\n",
    "df_dept72.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(df):\n",
    "    #Creating Features and Target\n",
    "    X = df.drop(['Weekly_Sales','log_revenue'], axis=1).values\n",
    "    y = df['Weekly_Sales'].values\n",
    "\n",
    "    #Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    #Create the Regression model:\n",
    "    linear = LinearRegression()\n",
    "    linear.fit(X_train, y_train)\n",
    "\n",
    "    #Making predictions\n",
    "    y_pred = linear.predict(X_test)\n",
    "    \n",
    "    y_true = y_test\n",
    "    \n",
    "    print(mean_absolute_error(y_true, y_pred))\n",
    "    \n",
    "fit_model(df_dept72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept72.to_csv(r'C:\\Users\\songs\\Desktop\\Springboard Files\\Capstone 2\\data\\Interim\\train_all_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
